{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c9cc90-7ab8-4a70-aa64-42b39999d9c9",
   "metadata": {},
   "source": [
    "# ü™Ñ Mulit-Agent Generative Formalization: Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c3d61-f779-42ba-838c-de41c014dd8a",
   "metadata": {},
   "source": [
    "## üìë About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc8022-ad0f-45df-8457-7ffcc5068439",
   "metadata": {},
   "source": [
    "Mulit-Agent Generative Formalization (**MAGiF**, formerly GAMA) is a Python- and Prolog-based simulator that enables users to create, simulate, and analyze strategic interactions using autoformalizing agents. The project supports game-theoretic experiments and includes tools for validating autoformalized Prolog programs. Currently, it supports 2√ó2 simultaneous-move games, but its modular architecture allows for extensions to other types of games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fdfd17-f361-49bb-991c-c345246b8cb1",
   "metadata": {},
   "source": [
    "## 1. üîß Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1e70b-b116-4a54-a514-c0f07a51272d",
   "metadata": {},
   "source": [
    "To set up the tutorial, run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39023013-cecf-45d4-af73-c0aafb23237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from IPython.display import Markdown, display\n",
    "    display(Markdown(\"\"\"\n",
    "> ‚ö†Ô∏è **This notebook is read-only.**\n",
    ">\n",
    "> To save your own editable version, go to:\n",
    ">\n",
    "> `File ‚Üí Save a copy in Drive`\n",
    ">\n",
    "> Then work from that copy so your changes are saved!\n",
    "    \"\"\"))\n",
    "else:\n",
    "    print(\"Local environment detected ‚Äî no need to save a copy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ddac9f-ee29-4bfa-b965-b217744ce61b",
   "metadata": {},
   "source": [
    "Enter your OpenAI API key below. If you do not have one, leave the field blank. Features that require API calls will be marked with ‚ö†Ô∏è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740be210-21b3-4234-aac6-f81000ccc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_in_colab():\n",
    "    return 'google.colab' in sys.modules\n",
    "\n",
    "if running_in_colab():\n",
    "    print(\"üì¶ Running in Colab...\")\n",
    "\n",
    "    # 1. Install system dependencies\n",
    "    !sudo apt-get update -qq\n",
    "    !sudo apt-get install -y swi-prolog\n",
    "\n",
    "    # 2. Clone repo and change into it\n",
    "    project_dir = Path(\"/content/GAMA\")\n",
    "    if not os.path.exists(project_dir):\n",
    "        !git clone --depth 1 https://github.com/dicelab-rhul/GAMA.git /content/GAMA\n",
    "    %cd /content/GAMA/tutorial\n",
    "\n",
    "    # 3. Install Python dependencies (editable mode)\n",
    "    !pip install -e .\n",
    "\n",
    "    sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "    # 5. Ask user for OpenAI key\n",
    "    import getpass\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your OpenAI API key:\")\n",
    "else:\n",
    "    print(\"üíª Running locally.\")\n",
    "\n",
    "    project_root = Path().resolve().parent\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "    if \"OPENAI_API_KEY\" not in os.environ:\n",
    "        raise EnvironmentError(\"Please set your OPENAI_API_KEY in the environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c9dc0-5f2a-42db-a311-86eb4cbd3119",
   "metadata": {},
   "source": [
    "Load the required modules and configuration data from a config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15249841-076e-427f-9e7a-e326634a7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import itertools\n",
    "import logging\n",
    "from magif.agent.agent import Agent\n",
    "from magif.environment.agent_pool import AgentPool\n",
    "from magif.environment.environment import Environment\n",
    "from magif.utils.data_object import DataObject\n",
    "from magif.utils.utils import AgentStatus, Mode, read_file, normalize_path, generate_agent_name\n",
    "from magif.utils.setup_logger import logger\n",
    "from magif.utils.validator import Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b600b-ed10-49ce-8e17-ea6f0d8ad687",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug('Tutorial')\n",
    "config = configparser.ConfigParser()\n",
    "config.read(normalize_path(\"tutorial/CONFIG/tutorial_config.ini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0ec82-8731-47c9-9a29-ac5069bf37bc",
   "metadata": {},
   "source": [
    "## 2. ü§ñ The Agent Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35d43a-38f3-4ad1-8a73-6e0c3a6a36aa",
   "metadata": {},
   "source": [
    "An agent comprises an autoformalization module utilizing an LLM, a mind containing the formal representation of a game and a strategy, and a memory that stores the history of moves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e75c643-ca14-4b93-95d5-f8160e035f8d",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"DATA/assets/agent_model.png\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c33f60-d01d-4b00-892c-a41e09357630",
   "metadata": {},
   "source": [
    "Both the game and the strategy can be either defined using pre-existing rules or autoformalized from an interaction scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb32443-268d-43a7-8c3e-86acbd3b41be",
   "metadata": {},
   "source": [
    "### üöÄ Let's interact with our first agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea45c2d-0db9-4212-962d-dd9907a8f555",
   "metadata": {},
   "source": [
    "We load a predefined PD agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96df0b4-4427-4bde-8c8a-0fbf85fbef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_json = normalize_path(config.get(\"Paths\", \"AGENT_JSON\")) # get the path to the agent from a json file\n",
    "agent = Agent(agent_json=agent_json, autoformalization_on=False) # create an agent by providing a path to a json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8965d524-2535-4dda-95b9-5c6a6ca06ca0",
   "metadata": {},
   "source": [
    "Let's inspect the agent by calling the `describe` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25a4f4-cd67-4e80-a0a5-2e35d91fe00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ad62c-cbcc-4bf1-a396-242f7bd135b2",
   "metadata": {},
   "source": [
    "We can print the agent‚Äôs formal game representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3ad30-49ab-4e1b-8e90-35990a566851",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2441e7b-fec1-47c5-8602-be4100366cfe",
   "metadata": {},
   "source": [
    "Print only the payoffs in the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2456e-6102-489c-89d3-b4126eaee557",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_game(payoffs_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023c292-f27f-44bc-99cc-e470b0bf552c",
   "metadata": {},
   "source": [
    "Print the agent's strategy representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86370bbf-d42d-4857-8588-af19e5745621",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2f50e-fe2b-4eb1-bea3-4bdff40c0c50",
   "metadata": {},
   "source": [
    "---\n",
    "An agent acts (performs an action), observes the opponent‚Äôs move, and updates its state. These steps are handled by the `mind`. Let‚Äôs have the agent act first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f07646-55d3-42d3-8db0-bb6e195012a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.mind.act()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f20655-125a-4831-ba03-a40be65d8388",
   "metadata": {},
   "source": [
    "The agent selected `silent`, which is its default action, performed in the absence of any opponent actions in memory. Now it's our turn to act:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f0a52-0010-4c75-99e0-2ed1b6dd6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_move = 'confess'\n",
    "agent.mind.observe(our_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c697db0-cf2a-4dee-bdbf-9a9ad2bdfcff",
   "metadata": {},
   "source": [
    "After observing the opponent's move, the agent updates its state using the `think` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed7225-19b1-4f35-a372-3ce2131a4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.mind.think()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca759e1-e8a6-4c9d-9e73-35243026a994",
   "metadata": {},
   "source": [
    "**Note:** In this example, the agent acted first, followed by our action. However, in the standard Prisoner's Dilemma (PD), both players are assumed to act simultaneously and independently. This is how agents take actions in the tournament implementation (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c5b00-be33-4ccf-9d44-10acff5d1456",
   "metadata": {},
   "source": [
    "Let's see what action our agent is going to take now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2aaead-45b2-4759-9bb3-406231aaaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.mind.act()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39680790-e55c-40a2-9ff4-05c494be9758",
   "metadata": {},
   "source": [
    "Following the tit-for-tat strategy, the agent responded by replicating our previous action and chose to confess. Let‚Äôs now stay silent and observe the resulting payoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17198760-daec-4023-bb39-4160ddb94faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.mind.observe('silent')\n",
    "agent.mind.think()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54fa27-29ab-4e3f-b8ef-70c9af676600",
   "metadata": {},
   "source": [
    "Finally, let's release the solver thread and remove the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f4f09-51f8-44cb-821d-b5fe75b129c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.release_solver()\n",
    "del agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea2f9a-0d9a-4ccf-8326-5b0636fcf2ce",
   "metadata": {},
   "source": [
    "### üöÄ Let's autoformalize! (‚ö†Ô∏è this section requires an API key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b67e7b-7b52-4e28-8531-72c965059efb",
   "metadata": {},
   "source": [
    "The core idea behind the framework is to streamline the development of multi-agent simulations by autoformalizing natural language interaction descriptions into formal representations that can be used by an agent's mind to reason about the interaction. Let's test this idea in practice. For this exercise, we will use a real-life scenario that can be modeled as a Prisoner's Dilemma (PD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0e03c-d7d6-465b-9d69-2e948664fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_description = \"Two employees are working on a joint project and must decide whether to share all their innovative ideas or keep some to themselves for credit. If both share openly, the project flourishes and they achieve great results, earning joint recognition. If one shares while the other withholds, the sharer contributes more but feels exploited, while the withholder benefits more and gains more recognition. If neither shares openly, the project suffers, and they both receive mediocre evaluations.\"\n",
    "print(game_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361271a9-edc8-4768-bf33-16d8e4cd3dfb",
   "metadata": {},
   "source": [
    "---\n",
    "First, we will load the prompt template we'll use to formalize this game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec2d56-f733-422c-b6b8-32d58e91cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_path = normalize_path(config.get(\"Paths\", \"GAME_TEMPLATE_PATH\"))\n",
    "prompt_template = read_file(prompt_template_path)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7034c53f-aa8a-4746-bf8e-133634b57fc7",
   "metadata": {},
   "source": [
    "---\n",
    "We use one-shot learning, utilizing the natural language description of the Prisoner's Dilemma (PD) and its Prolog representation as an example. Now, we will add our previously defined interaction scenario to the prompt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66eced5-24b6-41c7-82be-24c486fab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(game_description=game_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cc896-b41e-41d2-a506-f359ba434366",
   "metadata": {},
   "source": [
    "We will also need a feedback prompt template in case there are syntactic errors in the generated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcd34b-ad9d-46dd-b81a-5b3aba500146",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_template_path = normalize_path(config.get(\"Paths\", \"FEEDBACK_TEMPLATE_PATH\"))\n",
    "feedback_prompt=read_file(feedback_template_path)\n",
    "print(feedback_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63118fc-5ac3-41f5-94c8-34c0b17bab0e",
   "metadata": {},
   "source": [
    "---\n",
    "Now we can create a `DataObject` that specifies the game representation should be autoformalized from a natural language description using the provided prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8501f-d0a4-462f-b34e-ffb85e3d45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data = DataObject(nl_description=game_description, instruction_prompt=prompt,\n",
    "\t\t\t\t\t\t\t   feedback_prompt=feedback_prompt, mode=Mode.AUTOFORMALIZATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa91f75-de25-47ac-90ac-e97d6606c76a",
   "metadata": {},
   "source": [
    "The agent‚Äôs strategy will be loaded from a predefined file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7ea46-7d4a-40a7-89ef-0ad486460b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tit_for_tat_path = normalize_path(config.get(\"Paths\", \"STRATEGY_PATH\"))\n",
    "strategy_data = DataObject(rules_path=tit_for_tat_path, mode=Mode.RULES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbe64f-1d8c-43e1-ba36-1ce567dc5170",
   "metadata": {},
   "source": [
    "Now we create an agent by providing the game data (a natural language description to autoformalize), the strategy data (predefined rules for tit-for-tat), and the maximum number of attempts to generate syntactically correct code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05666230-4ee9-4731-a2a1-a41c1244686f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = Agent(game_data, strategy_data, max_attempts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fce80-29c6-41cc-8b3d-3d19c153d447",
   "metadata": {},
   "source": [
    "Let's check the agent's status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df4554-755c-44e9-835f-1073a0180e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fce5b0-16ba-422c-8c8c-49632be69cc2",
   "metadata": {},
   "source": [
    "If it's syntactically correct, we can try interacting with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9236a5-8699-48b6-97d0-825c845e776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent.status == AgentStatus.CORRECT:\n",
    "    moves = agent.game.game_moves\n",
    "    \n",
    "    agent.mind.act()\n",
    "    agent.mind.observe(moves[0])\n",
    "    agent.mind.think()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78beba44-95dd-4b90-8d87-8f1a2b6ae5ce",
   "metadata": {},
   "source": [
    "And inspect the payoff matrix to compare it with the original description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674831b-2f9b-48e3-92f8-daefdd27f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent.status == AgentStatus.CORRECT:\n",
    "    print(game_description, end=\"\\n\\n\")\n",
    "    agent.print_game(payoffs_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea3512-f3c5-4eec-9af9-08b04da9a6b7",
   "metadata": {},
   "source": [
    "---\n",
    "You may notice that manually comparing the interaction description to the generated payoff matrix is not the most effective way to evaluate the results of autoformalization. This issue is addressed in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e877d-0aef-417a-86f7-bcd4c85d6c32",
   "metadata": {},
   "source": [
    "## 3. üèÜ The Tournament"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264a1f9-7c10-45e9-9d79-2dac104e1a9e",
   "metadata": {},
   "source": [
    "Upon creation, the agent is validated for syntactic correctness. This, however, does not guarantee runtime correctness‚Äîfor example, parts of the code necessary for selecting an action may be missing. Semantic correctness‚Äîthat is, whether the formal representation of the game corresponds to its natural language description‚Äîis also undetermined. The simulation allows for runtime validation, as well as semantic validation if the target payoffs for the given game are known:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c623b0-4dda-4cc4-84be-af1d1cae5c87",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"DATA/assets/gama.png\" width=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6140763-a36f-4b72-8d6c-2beab768e7df",
   "metadata": {},
   "source": [
    "### üöÄ Let's play with autoformalized agents! (‚ö†Ô∏è this section requires an API key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffae66b-275e-4056-a539-0bcc05df59f6",
   "metadata": {},
   "source": [
    "We will autoformalize and validate an interaction scenario corresponding to the Battle of the Sexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d65616-ba6c-47b4-b671-fe35a8e3126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_description = \"Two roommates are deciding whether to watch a comedy or an action movie. One prefers comedies, while the other loves action films. However, they both value watching a movie together more than watching alone. If they agree on a comedy, the comedy enthusiast gets 2 points, and the action lover gets 1 point. If they agree on an action movie, the action lover gets 2 points, and the comedy enthusiast gets 1 point. If they choose different genres, neither watches a movie, and they both score 0 points.\"\n",
    "print(bos_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fc67d-36ac-440e-8978-85bf21c49256",
   "metadata": {},
   "source": [
    "---\n",
    "Let's set the parameters for the agent and the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4b6c0-0524-4200-9b55-d4b7ec292ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the tournament\n",
    "logdir = normalize_path(config.get(\"Paths\", \"OUT_DIR\")) # output logs directory\n",
    "num_rounds = 4 # number of tournament rounds\n",
    "agent_num = 5 # number of agents that will try to autoformalize the scenario\n",
    "target_payoff = 3 # target total payoff for an agent after 4 rounds of tit-for-tat vs anti-tit-for-tat\n",
    "\n",
    "# Parameter of an agent\n",
    "max_attempts = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c653776-7b50-4dcd-a29b-260655906a4f",
   "metadata": {},
   "source": [
    "Now we create an `AgentPool` object and populate it with agents that have autoformalized the interaction description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75578ef2-62f4-45c5-b58b-a23c4719e337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_pool = AgentPool() # agent pool object to manage agents participating in the tournament\n",
    "\n",
    "for i in range(agent_num):\n",
    "    prompt = prompt_template.format(game_description=bos_description)\n",
    "    \n",
    "    game_data = DataObject(nl_description=bos_description, instruction_prompt=prompt,\n",
    "\t\t\t\t\t\t\t\t   feedback_prompt=feedback_prompt, mode=Mode.AUTOFORMALIZATION)\n",
    "    strategy_data = DataObject(rules_path=tit_for_tat_path, mode=Mode.RULES_PATH)\n",
    "    \n",
    "    agent = Agent(game_data, strategy_data, max_attempts=5)\n",
    "    agent_pool.add_agent(agent)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7409bbe-38ff-4b0e-b9e3-8f1ec8d52050",
   "metadata": {},
   "source": [
    "To validate autoformalization, agents that generated syntactically valid code will play a tournament against their clones using the anti-tit-for-tat strategy. This setup ensures that all combinations of actions in the game are tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da72e85b-37e7-483c-b2b2-67e6a7b35aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_agents_num = len(agent_pool.valid_agents) # determine the number of syntactically valid agents\n",
    "\n",
    "# Add copies of an agent with tat-for-tit strategy\n",
    "for i in range(valid_agents_num):\n",
    "\tagent = agent_pool.valid_agents[i]\n",
    "\tclone = agent.clone(agent_json)\n",
    "\n",
    "\tagent_pool.add_agent(clone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc08006-7ecb-4879-b15c-b91adeda97d9",
   "metadata": {},
   "source": [
    "Finally, we need to define a matchmaker function that determines the matching protocol for the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045a715-4a0d-4fa6-857c-68e4fd53f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_maker = lambda agents: [(agents[i], agents[i+valid_agents_num]) for i in range(valid_agents_num)] #each valid agent is paired with its clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d6acb-0ae5-4f17-91e5-f420c42ace8d",
   "metadata": {},
   "source": [
    "We create a `Tournament` instance to manage the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca5e96-6833-4d56-a401-faf471c2e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament = Environment(\n",
    "    \t\tagent_pool=agent_pool,\n",
    "\t\t\tnum_rounds=num_rounds,\n",
    "\t\t\tmatch_maker=match_maker,\n",
    "            target_payoffs=valid_agents_num*[target_payoff]\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38bdd7-e648-4a28-afc2-dd69138c7056",
   "metadata": {},
   "source": [
    "We run the tournament and retrieve the winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf9065-9711-48da-950c-daab21673d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tournament.play_tournament()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1505b3b-ecf2-4385-a120-07b398392331",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_pool.truncate_pool(valid_agents_num)\n",
    "tournament.get_winners()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ae8e2-e741-452d-ab15-7266b93747d9",
   "metadata": {},
   "source": [
    "Now we log the results to validate the semantic correctness of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a947cb-4e3e-42e0-9146-612ed890738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament.log_tournament(experiment_dir=logdir, tournament_name=\"bs_test_tournament\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32e62cb-48a9-4de3-a394-3a67fe25f2b1",
   "metadata": {},
   "source": [
    "To validate semantic correctness, we use a custom `Validator` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bbbcc3-2a34-4bc7-87b6-254159cd7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_directory = logdir # directory with json files of agents created during the experiment\n",
    "matrices_filepath = normalize_path(\"tutorial/DATA/matrices.json\") # target payoff matrices\n",
    "validators_dir = normalize_path(\"DATA/EVAL\") # validation of payoff matrix structure if target payoffs are not available\n",
    "\n",
    "validator = Validator(agents_directory, matrices_filepath, validators_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762708d-4f60-4f48-8ae2-b0bb631ffd90",
   "metadata": {},
   "source": [
    "Let's run the validation and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c427671-1296-4978-8e59-7fbe37e372c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = validator.validate_all()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb463d8-776a-40d5-942b-b423590c4cd6",
   "metadata": {},
   "source": [
    "At the end, we clean up the `AgentPool` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e1edb-e048-40bb-8dd9-a6fc0edac802",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_pool.clean_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e6049-468d-412a-994b-77cb28789e8b",
   "metadata": {},
   "source": [
    "### üöÄ Let's play strategies!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80477c-541d-496c-af2f-a6bfb5cf3cda",
   "metadata": {},
   "source": [
    "Once we have validated the semantic correctness of the generated game representation, we can compare which strategy is, on average, the most successful for the game. We will use a valid agent generated previously for the above Battle-of-the-Sexes-like scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a47bc1-8a4d-4064-922d-5ccda1d609e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_json_path = normalize_path(config.get(\"Paths\", \"STRATEGY_AGENT_JSON\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4a3905-28f2-48f5-890e-88cad8181bbf",
   "metadata": {},
   "source": [
    "We will utilize the following strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fabfb4-c5c4-4b3c-9445-833796f84a01",
   "metadata": {},
   "source": [
    "| **Strategy**           | **Description**                                                                 |\n",
    "|------------------------|---------------------------------------------------------------------------------|\n",
    "| *anti-default-move*    | Always select the move that is the opposite of the default move.                |\n",
    "| *anti-tit-for-tat*     | Start with a default move. Then, select the move that is the opposite of the opponent's move in the previous round. |\n",
    "| *best-response*        | Start with a default move. Then, select a move that would give you the highest payoff in response to the opponent's move in the previous round. |\n",
    "| *default-move*         | Always select the default move.                                                 |\n",
    "| *random*               | Select one of the possible moves with uniform probability.                      |\n",
    "| *tit-for-tat*          | Start with a default move. Then, mirror the opponent's move in the previous round. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf559d-67e5-4095-9722-332cda733541",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_path = normalize_path(config.get(\"Paths\", \"STRATEGIES_PATH\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea0354-563d-4f49-b5d8-947d98a95f76",
   "metadata": {},
   "source": [
    "For each strategy, we add an agent copy with formalized game rules and that strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0988036-90ae-4125-bce9-7f461ccfc86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [os.path.join(strategies_path, strat_name) for strat_name in os.listdir(strategies_path)]\n",
    "agent_pool = AgentPool()\n",
    "agent = Agent(agent_json=agent_json_path, autoformalization_on=False) # agent with formalized game rules\n",
    "\n",
    "for strategy_path in strategies:\n",
    "    clone = agent.clone(agent_json_path, strategy_path)\n",
    "    agent_pool.add_agent(clone)\n",
    "\n",
    "agent.release_solver()\n",
    "del agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f475aaa-0f59-49a2-be9f-3bde81af5de4",
   "metadata": {},
   "source": [
    "We set the parameters of the tournament. This time, the tournament is round-robin, as we want to test each strategy against every other strategy, including itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb16a3d-597c-46a5-a4e0-5c810135a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 10\n",
    "match_maker = lambda agents: list(itertools.combinations_with_replacement(agents, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b62e1a-572c-4af3-8478-5636074561b7",
   "metadata": {},
   "source": [
    "In this case, target payoffs are not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf94156c-78a3-45c5-8038-ae08a14c4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament = Environment(\n",
    "        \tagent_pool=agent_pool,\n",
    "\t\t\tnum_rounds=num_rounds,\n",
    "\t\t\tmatch_maker=match_maker\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25015230-7d6c-4738-b4ff-2e71fdb720cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tournament.play_tournament()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c112d-2934-411a-8f43-fdbbe28ae020",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = tournament.get_winners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982444d-0fae-4241-adfe-8d4ceaf2b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Winners are:\")\n",
    "for winner in winners:\n",
    "    print(f\"Agent {winner.name} with strategy {winner.strategy_name} and payoff {winner.mind.get_total_payoff()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed887ae9-5b3d-4e2d-ac07-18bb051f4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_pool.clean_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a9b2b-5002-4d1e-a898-fa8090b7aaf6",
   "metadata": {},
   "source": [
    "# üë• 4. Case Studies (‚ö†Ô∏è this section requires an API key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838d347-2a37-4bd2-9828-8e24ad7ec5d0",
   "metadata": {},
   "source": [
    "We will create a function using the code from the examples above to autoformalize case studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ccf9f-4a16-4f24-8a5b-d881597e6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_study(game_description, num_rounds=4):\n",
    "    # Get prompt templates\n",
    "    prompt_template_path = normalize_path(config.get(\"Paths\", \"GAME_TEMPLATE_PATH\"))\n",
    "    prompt_template = read_file(prompt_template_path)\n",
    "    prompt = prompt_template.format(game_description=game_description)\n",
    "    feedback_template_path = normalize_path(config.get(\"Paths\", \"FEEDBACK_TEMPLATE_PATH\"))\n",
    "    feedback_prompt=read_file(feedback_template_path)\n",
    "    agent_json_path = normalize_path(config.get(\"Paths\", \"STRATEGY_AGENT_JSON\"))\n",
    "\n",
    "    # Game and strategy data\n",
    "    game_data = DataObject(nl_description=game_description, instruction_prompt=prompt,\n",
    "\t\t\t\t\t\t\t   feedback_prompt=feedback_prompt, mode=Mode.AUTOFORMALIZATION)\n",
    "\n",
    "    tit_for_tat_path = normalize_path(config.get(\"Paths\", \"STRATEGY_PATH\"))\n",
    "    strategy_data = DataObject(rules_path=tit_for_tat_path, mode=Mode.RULES_PATH)\n",
    "\n",
    "    # Create agent pool\n",
    "    agent_pool = AgentPool()\n",
    "    \n",
    "    # Create an agent\n",
    "    agent = Agent(game_data, strategy_data, max_attempts=5)\n",
    "\n",
    "    if agent.status != AgentStatus.CORRECT:\n",
    "        print(\"No syntactically correct agent created, try again!\")\n",
    "\n",
    "    else:\n",
    "        agent_pool.add_agent(agent) # add an agent to the pool\n",
    "\n",
    "        # Create and add clone:\n",
    "        agents_num = len(agent_pool.valid_agents)\n",
    "        clone = agent.clone(agent_json_path)\n",
    "        agent_pool.add_agent(clone)\n",
    "\n",
    "        match_maker = lambda agents: [(agents[i], agents[i+agents_num]) for i in range(agents_num)]\n",
    "\n",
    "        tournament = Environment(\n",
    "\t\t\tagent_pool=agent_pool,\n",
    "\t\t\tnum_rounds=num_rounds,\n",
    "\t\t\tmatch_maker=match_maker\n",
    "\t\t)\n",
    "\n",
    "        tournament.play_tournament()\n",
    "        \n",
    "        if agent.status != AgentStatus.CORRECT:\n",
    "            print(f\"Agent status is {agent.status}\")\n",
    "\n",
    "        else:\n",
    "            agent.describe()\n",
    "            agent.print_game(payoffs_only=True)\n",
    "\n",
    "        agent_pool.clean_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f8c84-5a3d-476e-bfb8-b398f111e41e",
   "metadata": {},
   "source": [
    "### Case study: The Cuban Missile Crisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b7a3a-03a2-434d-bdbd-0910e03b7138",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/9/96/Soviet_b-59_submarine.jpg\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3b5c6-0b28-4af3-becd-795bc4c2779b",
   "metadata": {},
   "source": [
    "[Source](https://en.wikipedia.org/wiki/Cuban_Missile_Crisis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b0085-5f9e-4569-af9d-00bdc49e8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_crisis = \"The Cuban Missile Crisis (...) was a 13-day confrontation between the governments of the United States and the Soviet Union, when American deployments of nuclear missiles in Italy and Turkey were matched by Soviet deployments of nuclear missiles in Cuba. The crisis lasted from 16 to 28 October 1962. The confrontation is widely considered the closest the Cold War came to escalating into full-scale nuclear war.\"\n",
    "nuclear_crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf545542-6053-4fc4-98e5-2acff2623f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_study(nuclear_crisis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeddf1b-189d-420e-82e8-11c3f12456a3",
   "metadata": {},
   "source": [
    "### Case study: Autonomous cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f7211-ec4d-476d-9020-ce37a0a945bb",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"DATA/assets/cars.png\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb15ff-e599-4379-8b00-6bdb68c90c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = \"Two autonomous cars, Car A and Car B, arrive at a four-way intersection at the same time. There is no traffic light or clear priority rule (e.g., right-of-way is ambiguous or not perfectly synchronized). Each car must decide between two strategies: proceed through the intersection without yielding or yield and let the other car go first. If both cars proceed simultaneously, a collision will occur; if both yield, a delay results.\"\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0b17e-c242-48b4-b789-7b8a20001903",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_study(cars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
